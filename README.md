# ğŸƒâ€â™‚ï¸ BipedalWalker-v3 Reinforcement Learning using PPO (Stable-Baselines3)

This project trains a Bipedal Walker agent using **Proximal Policy Optimization (PPO)** in the **Gymnasium BipedalWalker-v3** environment.  
The agent learns stable locomotion using neural network policies, trained on **Windows 11** with support for both **CPU** and **GPU (NVIDIA RTX)**.

---

# ğŸ“Œ Project Features
- PPO policy-gradient algorithm  
- Gymnasium + Box2D physics simulation  
- Training & testing pipeline  
- GPU acceleration (CUDA PyTorch)  
- Reward logging and plotting  
- Clean and reproducible project structure  

---

# ğŸ§© Tech Stack

| Component | Version |
|----------|---------|
| Python | 3.10.x |
| Gymnasium | Latest |
| Stable-Baselines3 | Latest |
| PyTorch | CPU or CUDA 12.1 |
| OS | Windows 10/11 |
| GPU | NVIDIA RTX 3050 Laptop GPU |

---

# ğŸ“ Project Structure

```
BipedalWalker-RL/
â”‚â”€â”€ train.py
â”‚â”€â”€ test.py
â”‚â”€â”€ plot_training.py
â”‚â”€â”€ check_gpu.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore
â”‚â”€â”€ training_rewards.npy
â”‚â”€â”€ models/                (optional)
â”‚â”€â”€ results/               (optional)
```

---

# ğŸ›  Installation

## 1ï¸âƒ£ Clone the Repository
```
git clone https://github.com/YOUR_USERNAME/BipedalWalker-RL.git  
cd BipedalWalker-RL
```

## 2ï¸âƒ£ Create Virtual Environment  
```
python -m venv venv
```

Activate:

**Windows**  
```
venv\Scripts\activate
```

**Linux**  
```
source venv/bin/activate
```

---

## 3ï¸âƒ£ Install Dependencies (CPU)
```
pip install -r requirements.txt
```

---

# âš¡ GPU Setup (CUDA)

## Step 1 â€” Remove CPU PyTorch  
```
pip uninstall torch torchvision torchaudio -y
```

## Step 2 â€” Install CUDA PyTorch 12.1  
```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## Step 3 â€” Check GPU 
```
python check_gpu.py
```

Expected:

Torch version: x.x.x  
CUDA available: True  
GPU Name: NVIDIA RTX 3050

---

# ğŸš€ Running the Project

## â­ Train Agent
```
python train.py
```

To force GPU:
```
model = PPO("MlpPolicy", env, device="cuda")
```

## â­ Test Agent
```
python test.py
```

## â­ Plot Rewards  
```
python plot_training.py
```

---

# ğŸ¤– Algorithm Used â€” PPO

**Proximal Policy Optimization (PPO)**  
- Stable policy updates  
- Works well on continuous control  
- Less sensitive to hyperparameters  
- Best choice for Bipedal Walker tasks  

---

# ğŸŒ Gymnasium Environments

### Normal Mode  
```
gym.make("BipedalWalker-v3")
```

### Hard Mode  
```
gym.make("BipedalWalkerHardcore-v3")
```

---

# ğŸ“ˆ Performance (Approx)

| Mode | Hardware | Time (500k steps) |
|------|----------|-------------------|
| Normal | CPU | ~50â€“60 mins |
| Normal | GPU | ~20â€“30 mins |
| Hardcore | GPU | 2â€“4 hours |

---

# ğŸ§ª check_gpu.py
```
import torch
print("Torch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))
else:
    print("Running on CPU only")
```
---

# ğŸ“¦ requirements.txt

- gymnasium[box2d]  
- stable-baselines3  
- pygame  
- matplotlib  
- numpy  

---

# ğŸ§¹ .gitignore  
- venv/  
- __pycache__/  
- *.npy  
- *.npz  
- *.zip  
- *.pt  
- *.pth  
- *.log  
- .DS_Store  

---

# ğŸ™Œ Credits  
- Gymnasium  
- Stable-Baselines3  
- PyTorch  
- Box2D  

---

# ğŸ Summary  
This repository contains a full PPO training pipeline for BipedalWalker-v3 with CPU & GPU support, clean structure, reward logging, and complete reproducibility.
